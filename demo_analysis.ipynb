{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8389b72",
   "metadata": {},
   "source": [
    "# scCytoTrek Demonstration Pipeline\n",
    "\n",
    "This notebook runs the full demonstration pipeline of the scCytoTrek package using standard Scanpy datasets (like pbmc3k) and outputs the results step by step. It is fully compatible with Linux, Windows, and macOS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "# Prevent macOS Apple Silicon (ARM64) segmentation faults and save memory/power \n",
    "# across all systems (Linux/Windows/Mac) by limiting pynndescent/arpack thread spawning\n",
    "sc.settings.n_jobs = 1\n",
    "\n",
    "import anndata as ad\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import scCytoTrek modules\n",
    "import sccytotrek as ct\n",
    "\n",
    "fig_dir = \"demo_figs\"\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "sc.settings.figdir = fig_dir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f15c4",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We will load the standard 3k PBMC dataset from 10x Genomics via `scanpy.datasets.pbmc3k()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4304b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading/Loading scanpy.datasets.pbmc3k()...\")\n",
    "adata = sc.datasets.pbmc3k()\n",
    "adata.var_names_make_unique()\n",
    "# Ensure matrix is dense to prevent sparse PCA segmentation faults on Mac ARM64/OpenBLAS\n",
    "import scipy.sparse as sp\n",
    "if sp.issparse(adata.X):\n",
    "    adata.X = adata.X.toarray()\n",
    "print(adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8faa0",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Quality Control\n",
    "\n",
    "We calculate standard QC metrics and visualize them. After identifying and removing doublets, the cells are subsampled (for speed/demonstration), normalized, and highly variable genes are isolated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa426dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run original QC calculation\n",
    "ct.preprocessing.calculate_qc_metrics(adata)\n",
    "ct.preprocessing.plot_qc_violins(adata, save_path=os.path.join(fig_dir, \"qc_violins.png\"))\n",
    "\n",
    "# Custom Doublet ID\n",
    "adata = ct.tools.identify_doublets(adata, expected_rate=0.04)\n",
    "\n",
    "# Filter out doublets\n",
    "adata = adata[~adata.obs['predicted_doublet']].copy()\n",
    "\n",
    "# Subsample (for demo purposes)\n",
    "adata = ct.preprocessing.subsample_cells(adata, target_cells=1500)\n",
    "\n",
    "# Standard Scanpy normalization block\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=1000)\n",
    "\n",
    "print(adata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19058225",
   "metadata": {},
   "source": [
    "## 3. Dimensionality Reduction & Clustering\n",
    "\n",
    "We perform PCA, build the spatial neighborhood graph, project the UMAP, and then run Leiden clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677dafb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sc.tl.pca(adata, svd_solver='arpack', n_comps=20)\n",
    "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=20)\n",
    "sc.tl.umap(adata)\n",
    "\n",
    "sc.tl.leiden(adata, resolution=0.5, key_added='leiden_0.5')\n",
    "fig = ct.plotting.dim_plot(adata, color='leiden_0.5', title=\"Leiden Clusters (UMAP)\", show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32cead5",
   "metadata": {},
   "source": [
    "## 4. Cell Type Assignment\n",
    "\n",
    "We score these clusters against a known marker dictionary for PBMCs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_dict = {\n",
    "    'T-cell': ['CD3D', 'CD3E', 'IL32'],\n",
    "    'B-cell': ['CD79A', 'MS4A1'],\n",
    "    'Monocyte': ['FCGR3A', 'LZTFL1'],\n",
    "    'NK-cell': ['GNLY', 'NKG7']\n",
    "}\n",
    "adata = ct.tools.score_cell_types(adata, marker_dict=marker_dict, groupby='leiden_0.5')\n",
    "\n",
    "fig = ct.plotting.dim_plot(adata, color='cell_type_prediction', title=\"Cell Type Mapping\", show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35384185",
   "metadata": {},
   "source": [
    "## 5. Trajectory Inference (Sandpile Network Entropy & Monocle3)\n",
    "\n",
    "We utilize advanced trajectory tools, including Sandpile entropy computations for critical state tipping points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_cell = adata.obs_names[0]\n",
    "sc.tl.dpt(adata) # Simple Pseudotime proxy\n",
    "# Sandpile Entropy Tipping Point Detection\n",
    "try:\n",
    "    tipping_res = ct.trajectory.compute_sandpile_entropy(adata, pseudotime_key='dpt_pseudotime', n_bins=20)\n",
    "    tipping_bin = tipping_res['tipping_point_bin']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(tipping_res['bins'], tipping_res['entropy'], marker='o', color='darkorange')\n",
    "    ax.axvline(tipping_bin, color='red', linestyle='--', label=f'Tipping Point (Bin {tipping_bin})')\n",
    "    ax.set_title(\"Sandpile Model: Network Entropy along Trajectory\")\n",
    "    plt.show()\n",
    "    \n",
    "    sc.pl.umap(adata, color='sandpile_entropy', cmap='magma', title='Sandpile Entropy (Tipping Points)', show=True)\n",
    "except Exception as e:\n",
    "    print(f\"Skipped tipping point due to error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65768532",
   "metadata": {},
   "source": [
    "## 6. Transcription Factor Enrichment\n",
    "\n",
    "We can dynamically calculate transcription factor enrichments using synthetic or derived networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1474031",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_genes = adata.var_names[:5].tolist()\n",
    "if len(valid_genes) >= 4:\n",
    "    tf_df = pd.DataFrame({\n",
    "        'tf': [valid_genes[0], valid_genes[0], valid_genes[1], valid_genes[1]],\n",
    "        'target': [valid_genes[2], valid_genes[3], valid_genes[2], valid_genes[3]],\n",
    "        'weight': [1.0, 0.8, -0.5, 0.9]\n",
    "    })\n",
    "    adata = ct.grn.run_tf_enrichment(adata, tf_network=tf_df, source_col='tf', target_col='target', min_expr_fraction=0.0)\n",
    "    sc.pl.umap(adata, color=f\"tf_score_{valid_genes[0]}\", cmap='viridis', title=f\"TF Enrichment: {valid_genes[0]}\", show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1c9a00",
   "metadata": {},
   "source": [
    "## 7. Differential Expression\n",
    "\n",
    "We perform Dropout-Adjusted DE across major cell clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = adata.obs['leiden_0.5'].unique()\n",
    "if len(groups) >= 2:\n",
    "    try:\n",
    "        de_res = ct.tools.dropout_adjusted_de(\n",
    "            adata, group_key='leiden_0.5', group1=groups[0], group2=groups[1], \n",
    "            out_csv=os.path.join(fig_dir, \"differential_expression_pbmc3k.csv\")\n",
    "        )\n",
    "        print(f\"Differentially expressed genes between {groups[0]} and {groups[1]} extracted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"DE skipped: {e}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
